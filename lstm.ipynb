{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv2D, Activation\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 6, 300)\n",
      "(370, 4)\n"
     ]
    }
   ],
   "source": [
    "# set parameters and load data\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "time_steps = 6\n",
    "features = 300\n",
    "\n",
    "features_path = 'input_vol.npy'\n",
    "labels_path = 'input_label.npy'\n",
    "\n",
    "X = np.load(features_path)\n",
    "Y = np.load(labels_path)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly shuffle data\n",
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X = X[s]\n",
    "Y = Y[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "train_X = X[0:296,:,:]\n",
    "test_X = X[297:369,:,:]\n",
    "\n",
    "train_Y = Y[0:296,:]\n",
    "test_Y = Y[297:369,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 160,804\n",
      "Trainable params: 160,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 296 samples, validate on 72 samples\n",
      "Epoch 1/100\n",
      "296/296 [==============================] - 4s - loss: 0.6699 - acc: 0.6841 - val_loss: 0.6205 - val_acc: 0.7014\n",
      "Epoch 2/100\n",
      "296/296 [==============================] - 0s - loss: 0.5766 - acc: 0.7078 - val_loss: 0.5660 - val_acc: 0.7049\n",
      "Epoch 3/100\n",
      "296/296 [==============================] - 0s - loss: 0.5195 - acc: 0.7542 - val_loss: 0.5376 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      "296/296 [==============================] - 0s - loss: 0.4690 - acc: 0.7804 - val_loss: 0.5335 - val_acc: 0.7431\n",
      "Epoch 5/100\n",
      "296/296 [==============================] - 0s - loss: 0.4146 - acc: 0.8100 - val_loss: 0.5288 - val_acc: 0.7604\n",
      "Epoch 6/100\n",
      "296/296 [==============================] - 0s - loss: 0.3774 - acc: 0.8328 - val_loss: 0.5620 - val_acc: 0.7326\n",
      "Epoch 7/100\n",
      "296/296 [==============================] - 0s - loss: 0.3357 - acc: 0.8530 - val_loss: 0.5758 - val_acc: 0.7292\n",
      "Epoch 8/100\n",
      "296/296 [==============================] - 0s - loss: 0.3228 - acc: 0.8632 - val_loss: 0.5710 - val_acc: 0.7292\n",
      "Epoch 9/100\n",
      "296/296 [==============================] - 0s - loss: 0.2985 - acc: 0.8725 - val_loss: 0.6019 - val_acc: 0.73960.873\n",
      "Epoch 10/100\n",
      "296/296 [==============================] - 0s - loss: 0.2741 - acc: 0.8860 - val_loss: 0.6383 - val_acc: 0.7292\n",
      "Epoch 11/100\n",
      "296/296 [==============================] - 0s - loss: 0.2547 - acc: 0.8961 - val_loss: 0.6619 - val_acc: 0.7396\n",
      "Epoch 12/100\n",
      "296/296 [==============================] - 0s - loss: 0.2344 - acc: 0.9029 - val_loss: 0.6632 - val_acc: 0.7326\n",
      "Epoch 13/100\n",
      "296/296 [==============================] - 1s - loss: 0.2137 - acc: 0.9122 - val_loss: 0.6918 - val_acc: 0.7292\n",
      "Epoch 14/100\n",
      "296/296 [==============================] - 0s - loss: 0.1863 - acc: 0.9291 - val_loss: 0.7245 - val_acc: 0.7326\n",
      "Epoch 15/100\n",
      "296/296 [==============================] - 0s - loss: 0.1844 - acc: 0.9316 - val_loss: 0.7688 - val_acc: 0.7292\n",
      "Epoch 16/100\n",
      "296/296 [==============================] - 0s - loss: 0.1923 - acc: 0.9291 - val_loss: 0.7683 - val_acc: 0.7361\n",
      "Epoch 17/100\n",
      "296/296 [==============================] - 0s - loss: 0.1613 - acc: 0.9426 - val_loss: 0.8061 - val_acc: 0.7222\n",
      "Epoch 18/100\n",
      "296/296 [==============================] - 0s - loss: 0.1526 - acc: 0.9443 - val_loss: 0.8265 - val_acc: 0.7326\n",
      "Epoch 19/100\n",
      "296/296 [==============================] - 0s - loss: 0.1461 - acc: 0.9459 - val_loss: 0.8613 - val_acc: 0.7153\n",
      "Epoch 20/100\n",
      "296/296 [==============================] - 0s - loss: 0.1280 - acc: 0.9527 - val_loss: 0.9137 - val_acc: 0.7118\n",
      "Epoch 21/100\n",
      "296/296 [==============================] - 0s - loss: 0.1468 - acc: 0.9510 - val_loss: 0.8753 - val_acc: 0.7222\n",
      "Epoch 22/100\n",
      "296/296 [==============================] - 0s - loss: 0.1158 - acc: 0.9620 - val_loss: 0.8924 - val_acc: 0.7222\n",
      "Epoch 23/100\n",
      "296/296 [==============================] - 0s - loss: 0.0970 - acc: 0.9730 - val_loss: 0.9596 - val_acc: 0.7187\n",
      "Epoch 24/100\n",
      "296/296 [==============================] - 0s - loss: 0.0962 - acc: 0.9696 - val_loss: 0.9790 - val_acc: 0.7118\n",
      "Epoch 25/100\n",
      "296/296 [==============================] - 0s - loss: 0.0932 - acc: 0.9662 - val_loss: 0.9999 - val_acc: 0.7083\n",
      "Epoch 26/100\n",
      "296/296 [==============================] - 0s - loss: 0.1023 - acc: 0.9688 - val_loss: 1.0674 - val_acc: 0.7014\n",
      "Epoch 27/100\n",
      "296/296 [==============================] - 0s - loss: 0.0945 - acc: 0.9688 - val_loss: 1.0201 - val_acc: 0.6875\n",
      "Epoch 28/100\n",
      "296/296 [==============================] - 0s - loss: 0.0864 - acc: 0.9713 - val_loss: 1.0481 - val_acc: 0.7118\n",
      "Epoch 29/100\n",
      "296/296 [==============================] - 0s - loss: 0.0837 - acc: 0.9721 - val_loss: 1.0655 - val_acc: 0.6910\n",
      "Epoch 30/100\n",
      "296/296 [==============================] - 0s - loss: 0.0901 - acc: 0.9688 - val_loss: 1.0506 - val_acc: 0.7118\n",
      "Epoch 31/100\n",
      "296/296 [==============================] - 1s - loss: 0.0795 - acc: 0.9738 - val_loss: 1.0840 - val_acc: 0.6944\n",
      "Epoch 32/100\n",
      "296/296 [==============================] - 0s - loss: 0.0784 - acc: 0.9688 - val_loss: 1.1073 - val_acc: 0.7153\n",
      "Epoch 33/100\n",
      "296/296 [==============================] - 0s - loss: 0.0790 - acc: 0.9688 - val_loss: 1.1359 - val_acc: 0.7049\n",
      "Epoch 34/100\n",
      "296/296 [==============================] - 0s - loss: 0.0635 - acc: 0.9755 - val_loss: 1.1528 - val_acc: 0.7049\n",
      "Epoch 35/100\n",
      "296/296 [==============================] - 0s - loss: 0.0693 - acc: 0.9764 - val_loss: 1.0984 - val_acc: 0.7118\n",
      "Epoch 36/100\n",
      "296/296 [==============================] - 0s - loss: 0.0529 - acc: 0.9856 - val_loss: 1.1201 - val_acc: 0.6944\n",
      "Epoch 37/100\n",
      "296/296 [==============================] - 0s - loss: 0.0565 - acc: 0.9831 - val_loss: 1.1274 - val_acc: 0.7083\n",
      "Epoch 38/100\n",
      "296/296 [==============================] - 0s - loss: 0.0392 - acc: 0.9907 - val_loss: 1.1170 - val_acc: 0.7257\n",
      "Epoch 39/100\n",
      "296/296 [==============================] - 1s - loss: 0.0502 - acc: 0.9873 - val_loss: 1.1235 - val_acc: 0.7222\n",
      "Epoch 40/100\n",
      "296/296 [==============================] - 1s - loss: 0.0450 - acc: 0.9873 - val_loss: 1.1717 - val_acc: 0.7118\n",
      "Epoch 41/100\n",
      "296/296 [==============================] - 2s - loss: 0.0461 - acc: 0.9856 - val_loss: 1.1408 - val_acc: 0.7118\n",
      "Epoch 42/100\n",
      "296/296 [==============================] - 1s - loss: 0.0327 - acc: 0.9916 - val_loss: 1.1393 - val_acc: 0.7222\n",
      "Epoch 43/100\n",
      "296/296 [==============================] - 1s - loss: 0.0445 - acc: 0.9865 - val_loss: 1.1850 - val_acc: 0.7188\n",
      "Epoch 44/100\n",
      "296/296 [==============================] - 1s - loss: 0.0481 - acc: 0.9856 - val_loss: 1.1671 - val_acc: 0.7222\n",
      "Epoch 45/100\n",
      "296/296 [==============================] - 1s - loss: 0.0408 - acc: 0.9873 - val_loss: 1.2282 - val_acc: 0.6979\n",
      "Epoch 46/100\n",
      "296/296 [==============================] - 1s - loss: 0.0347 - acc: 0.9924 - val_loss: 1.2141 - val_acc: 0.6979\n",
      "Epoch 47/100\n",
      "296/296 [==============================] - 1s - loss: 0.0313 - acc: 0.9932 - val_loss: 1.2332 - val_acc: 0.6944\n",
      "Epoch 48/100\n",
      "296/296 [==============================] - 1s - loss: 0.0303 - acc: 0.9907 - val_loss: 1.2442 - val_acc: 0.7014\n",
      "Epoch 49/100\n",
      "296/296 [==============================] - 1s - loss: 0.0274 - acc: 0.9958 - val_loss: 1.2731 - val_acc: 0.7014\n",
      "Epoch 50/100\n",
      "296/296 [==============================] - 1s - loss: 0.0328 - acc: 0.9890 - val_loss: 1.2318 - val_acc: 0.7014\n",
      "Epoch 51/100\n",
      "296/296 [==============================] - 1s - loss: 0.0308 - acc: 0.9916 - val_loss: 1.2754 - val_acc: 0.7222\n",
      "Epoch 52/100\n",
      "296/296 [==============================] - 1s - loss: 0.0346 - acc: 0.9890 - val_loss: 1.2782 - val_acc: 0.7153\n",
      "Epoch 53/100\n",
      "296/296 [==============================] - 0s - loss: 0.0333 - acc: 0.9916 - val_loss: 1.2997 - val_acc: 0.7049\n",
      "Epoch 54/100\n",
      "296/296 [==============================] - 0s - loss: 0.0268 - acc: 0.9932 - val_loss: 1.3083 - val_acc: 0.6875\n",
      "Epoch 55/100\n",
      "296/296 [==============================] - 1s - loss: 0.0313 - acc: 0.9924 - val_loss: 1.3649 - val_acc: 0.6875\n",
      "Epoch 56/100\n",
      "296/296 [==============================] - 0s - loss: 0.0258 - acc: 0.9924 - val_loss: 1.3056 - val_acc: 0.6910\n",
      "Epoch 57/100\n",
      "296/296 [==============================] - 1s - loss: 0.0491 - acc: 0.9831 - val_loss: 1.3461 - val_acc: 0.7083\n",
      "Epoch 58/100\n",
      "296/296 [==============================] - 1s - loss: 0.0310 - acc: 0.9899 - val_loss: 1.3178 - val_acc: 0.6910\n",
      "Epoch 59/100\n",
      "296/296 [==============================] - 1s - loss: 0.0248 - acc: 0.9932 - val_loss: 1.2940 - val_acc: 0.7049\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s - loss: 0.0300 - acc: 0.9899 - val_loss: 1.3217 - val_acc: 0.6944\n",
      "Epoch 61/100\n",
      "296/296 [==============================] - 1s - loss: 0.0221 - acc: 0.9949 - val_loss: 1.3202 - val_acc: 0.6979\n",
      "Epoch 62/100\n",
      "296/296 [==============================] - 0s - loss: 0.0214 - acc: 0.9924 - val_loss: 1.3117 - val_acc: 0.6979\n",
      "Epoch 63/100\n",
      "296/296 [==============================] - 0s - loss: 0.0259 - acc: 0.9932 - val_loss: 1.3409 - val_acc: 0.7118\n",
      "Epoch 64/100\n",
      "296/296 [==============================] - 0s - loss: 0.0120 - acc: 0.9975 - val_loss: 1.3224 - val_acc: 0.7083\n",
      "Epoch 65/100\n",
      "296/296 [==============================] - 1s - loss: 0.0099 - acc: 0.9983 - val_loss: 1.3562 - val_acc: 0.7014\n",
      "Epoch 66/100\n",
      "296/296 [==============================] - 1s - loss: 0.0108 - acc: 0.9992 - val_loss: 1.3454 - val_acc: 0.7049\n",
      "Epoch 67/100\n",
      "296/296 [==============================] - 1s - loss: 0.0152 - acc: 0.9958 - val_loss: 1.3239 - val_acc: 0.7292\n",
      "Epoch 68/100\n",
      "296/296 [==============================] - 1s - loss: 0.0199 - acc: 0.9958 - val_loss: 1.3582 - val_acc: 0.7153\n",
      "Epoch 69/100\n",
      "296/296 [==============================] - 0s - loss: 0.0149 - acc: 0.9941 - val_loss: 1.3697 - val_acc: 0.7153\n",
      "Epoch 70/100\n",
      "296/296 [==============================] - 1s - loss: 0.0170 - acc: 0.9958 - val_loss: 1.3870 - val_acc: 0.7049\n",
      "Epoch 71/100\n",
      "296/296 [==============================] - 0s - loss: 0.0118 - acc: 0.9975 - val_loss: 1.3682 - val_acc: 0.7188\n",
      "Epoch 72/100\n",
      "296/296 [==============================] - 0s - loss: 0.0128 - acc: 0.9966 - val_loss: 1.3658 - val_acc: 0.6910\n",
      "Epoch 73/100\n",
      "296/296 [==============================] - 0s - loss: 0.0122 - acc: 0.9975 - val_loss: 1.3517 - val_acc: 0.7361\n",
      "Epoch 74/100\n",
      "296/296 [==============================] - 0s - loss: 0.0083 - acc: 0.9983 - val_loss: 1.4260 - val_acc: 0.7049\n",
      "Epoch 75/100\n",
      "296/296 [==============================] - 1s - loss: 0.0165 - acc: 0.9958 - val_loss: 1.4129 - val_acc: 0.7083\n",
      "Epoch 76/100\n",
      "296/296 [==============================] - 1s - loss: 0.0198 - acc: 0.9958 - val_loss: 1.4577 - val_acc: 0.7153\n",
      "Epoch 77/100\n",
      "296/296 [==============================] - 0s - loss: 0.0243 - acc: 0.9924 - val_loss: 1.3835 - val_acc: 0.7188\n",
      "Epoch 78/100\n",
      "296/296 [==============================] - 0s - loss: 0.0216 - acc: 0.9941 - val_loss: 1.4132 - val_acc: 0.7257\n",
      "Epoch 79/100\n",
      "296/296 [==============================] - 0s - loss: 0.0118 - acc: 0.9966 - val_loss: 1.4363 - val_acc: 0.7153\n",
      "Epoch 80/100\n",
      "296/296 [==============================] - 0s - loss: 0.0185 - acc: 0.9949 - val_loss: 1.4272 - val_acc: 0.7187\n",
      "Epoch 81/100\n",
      "296/296 [==============================] - 0s - loss: 0.0196 - acc: 0.9949 - val_loss: 1.4476 - val_acc: 0.7118\n",
      "Epoch 82/100\n",
      "296/296 [==============================] - 0s - loss: 0.0106 - acc: 0.9983 - val_loss: 1.4074 - val_acc: 0.7187\n",
      "Epoch 83/100\n",
      "296/296 [==============================] - 0s - loss: 0.0082 - acc: 0.9983 - val_loss: 1.3868 - val_acc: 0.7257\n",
      "Epoch 84/100\n",
      "296/296 [==============================] - 0s - loss: 0.0065 - acc: 1.0000 - val_loss: 1.4571 - val_acc: 0.7118\n",
      "Epoch 85/100\n",
      "296/296 [==============================] - 0s - loss: 0.0148 - acc: 0.9958 - val_loss: 1.4718 - val_acc: 0.7049\n",
      "Epoch 86/100\n",
      "296/296 [==============================] - 0s - loss: 0.0071 - acc: 0.9992 - val_loss: 1.4571 - val_acc: 0.7153\n",
      "Epoch 87/100\n",
      "296/296 [==============================] - 0s - loss: 0.0087 - acc: 0.9966 - val_loss: 1.4781 - val_acc: 0.7153\n",
      "Epoch 88/100\n",
      "296/296 [==============================] - 0s - loss: 0.0080 - acc: 0.9983 - val_loss: 1.4877 - val_acc: 0.7153\n",
      "Epoch 89/100\n",
      "296/296 [==============================] - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 1.4722 - val_acc: 0.7118\n",
      "Epoch 90/100\n",
      "296/296 [==============================] - 0s - loss: 0.0087 - acc: 0.9983 - val_loss: 1.4789 - val_acc: 0.7153\n",
      "Epoch 91/100\n",
      "296/296 [==============================] - 0s - loss: 0.0276 - acc: 0.9932 - val_loss: 1.4080 - val_acc: 0.7361\n",
      "Epoch 92/100\n",
      "296/296 [==============================] - 0s - loss: 0.0224 - acc: 0.9941 - val_loss: 1.4188 - val_acc: 0.7257\n",
      "Epoch 93/100\n",
      "296/296 [==============================] - 0s - loss: 0.0187 - acc: 0.9949 - val_loss: 1.4610 - val_acc: 0.7292\n",
      "Epoch 94/100\n",
      "296/296 [==============================] - 0s - loss: 0.0129 - acc: 0.9966 - val_loss: 1.4155 - val_acc: 0.7222\n",
      "Epoch 95/100\n",
      "296/296 [==============================] - 0s - loss: 0.0080 - acc: 0.9983 - val_loss: 1.4302 - val_acc: 0.7257\n",
      "Epoch 96/100\n",
      "296/296 [==============================] - 0s - loss: 0.0053 - acc: 0.9992 - val_loss: 1.4620 - val_acc: 0.7187\n",
      "Epoch 97/100\n",
      "296/296 [==============================] - 0s - loss: 0.0039 - acc: 0.9992 - val_loss: 1.5133 - val_acc: 0.7118\n",
      "Epoch 98/100\n",
      "296/296 [==============================] - 0s - loss: 0.0049 - acc: 0.9992 - val_loss: 1.4979 - val_acc: 0.7257\n",
      "Epoch 99/100\n",
      "296/296 [==============================] - 0s - loss: 0.0070 - acc: 0.9983 - val_loss: 1.4575 - val_acc: 0.7222\n",
      "Epoch 100/100\n",
      "296/296 [==============================] - 0s - loss: 0.0092 - acc: 0.9975 - val_loss: 1.4714 - val_acc: 0.7257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ceebf3ac8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build LSTM layers and train model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, dropout= 0.2, input_shape=(time_steps, features)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(train_X, train_Y, validation_data=(test_X, test_Y), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.57%\n"
     ]
    }
   ],
   "source": [
    "# score model and log accuracy\n",
    "scores = model.evaluate(test_X, test_Y, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.08784631e-02,   7.00037344e-04,   4.70727507e-04,\n",
       "          9.93089497e-01],\n",
       "       [  1.02481656e-01,   7.57343078e-04,   3.80564743e-04,\n",
       "          4.31274122e-04],\n",
       "       [  7.10452301e-03,   5.75981743e-04,   9.94173944e-01,\n",
       "          6.33051211e-04],\n",
       "       [  1.46325689e-03,   1.10147474e-03,   9.83400166e-01,\n",
       "          6.28310489e-04],\n",
       "       [  9.94987369e-01,   2.76276213e-03,   5.08848694e-04,\n",
       "          1.46745369e-04],\n",
       "       [  6.09508774e-04,   3.35921301e-04,   4.75930312e-04,\n",
       "          3.20658495e-04],\n",
       "       [  5.48839569e-04,   2.86244031e-04,   8.36329767e-04,\n",
       "          2.98320025e-04],\n",
       "       [  1.97452307e-02,   1.01756793e-03,   5.32943271e-02,\n",
       "          7.23019693e-05],\n",
       "       [  5.56171057e-04,   9.96908486e-01,   1.08278135e-03,\n",
       "          9.94611382e-01],\n",
       "       [  9.82885480e-01,   5.04315540e-04,   3.73256952e-03,\n",
       "          1.52357398e-02],\n",
       "       [  1.60589423e-02,   3.83963548e-02,   7.94255137e-01,\n",
       "          4.11617293e-05],\n",
       "       [  9.92037296e-01,   8.32000554e-01,   2.24432815e-02,\n",
       "          9.98734891e-01],\n",
       "       [  8.12440994e-04,   2.08915953e-04,   7.31862150e-04,\n",
       "          1.64540559e-02],\n",
       "       [  2.05017766e-03,   9.97850180e-01,   5.63394744e-03,\n",
       "          9.99734104e-01],\n",
       "       [  2.42540333e-03,   6.13248267e-05,   1.28580436e-01,\n",
       "          2.71459343e-04],\n",
       "       [  3.21881816e-04,   4.35055757e-04,   5.40557725e-04,\n",
       "          4.01612720e-04],\n",
       "       [  1.26848754e-03,   4.86443139e-04,   5.95122933e-01,\n",
       "          9.92876589e-01],\n",
       "       [  7.39180774e-04,   3.52029077e-04,   5.51776902e-04,\n",
       "          2.77600018e-04],\n",
       "       [  1.71981938e-03,   7.31589447e-04,   4.36605606e-03,\n",
       "          1.07768993e-03],\n",
       "       [  3.08552728e-04,   1.06346130e-03,   2.29677215e-04,\n",
       "          6.40117889e-03],\n",
       "       [  1.33809179e-01,   9.95066762e-01,   4.29770816e-03,\n",
       "          2.65653187e-04],\n",
       "       [  2.31953827e-03,   7.58116227e-03,   4.37846138e-05,\n",
       "          1.55048259e-02],\n",
       "       [  3.63562343e-04,   3.99331067e-04,   6.11203955e-04,\n",
       "          3.60330043e-04],\n",
       "       [  1.08962669e-03,   6.97790645e-04,   2.57862557e-04,\n",
       "          4.47573286e-04],\n",
       "       [  9.74059165e-01,   5.49159537e-04,   9.99002397e-01,\n",
       "          7.12733194e-02],\n",
       "       [  8.02297262e-04,   1.82739587e-03,   4.78605321e-03,\n",
       "          9.99513030e-01],\n",
       "       [  1.48277803e-04,   1.95802143e-03,   1.20803760e-03,\n",
       "          1.12012168e-03],\n",
       "       [  3.87463951e-04,   9.78814781e-01,   1.13312900e-03,\n",
       "          4.71341610e-03],\n",
       "       [  8.68043125e-01,   1.65005797e-04,   8.88831913e-01,\n",
       "          4.21410687e-02],\n",
       "       [  7.07382453e-04,   7.09315836e-01,   9.51558650e-01,\n",
       "          9.95710015e-01],\n",
       "       [  2.52212700e-03,   9.78825390e-01,   4.12329071e-04,\n",
       "          5.28348098e-03],\n",
       "       [  3.88948334e-04,   1.39114994e-03,   9.82100308e-01,\n",
       "          8.82419944e-01],\n",
       "       [  8.58808984e-04,   4.06057341e-03,   4.04654071e-04,\n",
       "          3.40669125e-04],\n",
       "       [  3.93012102e-04,   5.54196478e-04,   5.89278992e-04,\n",
       "          5.54605445e-04],\n",
       "       [  4.23524575e-03,   9.39802383e-04,   9.88323152e-01,\n",
       "          9.96843338e-01],\n",
       "       [  4.31974593e-04,   3.26901383e-04,   5.95443067e-04,\n",
       "          3.05922964e-04],\n",
       "       [  2.19979640e-02,   3.83664883e-04,   1.00540780e-01,\n",
       "          3.86772153e-04],\n",
       "       [  5.89765317e-04,   1.69148945e-04,   1.40944414e-03,\n",
       "          3.33300704e-04],\n",
       "       [  4.30910708e-03,   2.66701775e-03,   9.06458616e-01,\n",
       "          1.28410655e-04],\n",
       "       [  4.11511570e-01,   3.06484057e-04,   9.99567688e-01,\n",
       "          1.32099926e-01],\n",
       "       [  2.55648862e-03,   9.96491373e-01,   9.99147177e-01,\n",
       "          9.99724686e-01],\n",
       "       [  5.99510095e-04,   3.11041396e-04,   6.26876426e-04,\n",
       "          2.90394441e-04],\n",
       "       [  1.94012347e-04,   2.29890249e-03,   1.79071367e-01,\n",
       "          1.21001783e-03],\n",
       "       [  4.48352162e-04,   9.70630348e-03,   5.10369102e-03,\n",
       "          9.99456942e-01],\n",
       "       [  3.66022083e-04,   3.43032385e-04,   6.44670043e-04,\n",
       "          3.33137403e-04],\n",
       "       [  1.92629683e-04,   3.25636081e-02,   3.32495518e-04,\n",
       "          2.44453177e-03],\n",
       "       [  9.27767992e-01,   6.27285510e-04,   9.90347385e-01,\n",
       "          4.56615700e-04],\n",
       "       [  1.00545806e-03,   1.11615029e-03,   5.82258450e-04,\n",
       "          9.98219907e-01],\n",
       "       [  2.91234581e-03,   9.98301268e-01,   9.98851418e-01,\n",
       "          9.99623179e-01],\n",
       "       [  9.98228848e-01,   2.58342177e-03,   6.28932379e-04,\n",
       "          4.08039050e-04],\n",
       "       [  4.07562242e-04,   3.33210133e-04,   6.18670660e-04,\n",
       "          3.06579022e-04],\n",
       "       [  3.30656674e-03,   9.95063245e-01,   9.99423265e-01,\n",
       "          9.99667764e-01],\n",
       "       [  1.56984560e-03,   9.75305021e-01,   4.00941004e-04,\n",
       "          1.14643471e-02],\n",
       "       [  2.45010655e-04,   5.98171726e-04,   4.27393650e-04,\n",
       "          5.82548440e-04],\n",
       "       [  1.27157406e-03,   2.53550825e-04,   9.40237284e-01,\n",
       "          8.81674290e-01],\n",
       "       [  3.46740359e-03,   1.55229078e-04,   5.57608437e-04,\n",
       "          7.39852025e-04],\n",
       "       [  2.81503220e-04,   1.16782542e-03,   2.44371337e-03,\n",
       "          9.98106480e-01],\n",
       "       [  3.02364555e-04,   9.90828633e-01,   6.26415364e-04,\n",
       "          8.09094548e-01],\n",
       "       [  9.56030190e-03,   7.83002004e-03,   8.78980645e-05,\n",
       "          3.44930519e-03],\n",
       "       [  5.96402407e-01,   3.08713014e-03,   5.02168201e-04,\n",
       "          1.08590454e-01],\n",
       "       [  8.13249208e-04,   3.68230540e-04,   4.62470605e-04,\n",
       "          3.75270029e-04],\n",
       "       [  1.97802354e-02,   9.83013749e-01,   9.99090910e-01,\n",
       "          4.79416514e-04],\n",
       "       [  9.98414874e-01,   2.28179572e-03,   9.97562766e-01,\n",
       "          8.42005849e-01],\n",
       "       [  9.80994761e-01,   1.40080100e-03,   9.99062717e-01,\n",
       "          3.74673586e-03],\n",
       "       [  2.74399470e-04,   7.63489399e-04,   4.44714096e-04,\n",
       "          3.48823494e-04],\n",
       "       [  8.26201634e-04,   1.18002025e-02,   4.24095318e-02,\n",
       "          9.99756038e-01],\n",
       "       [  2.67788244e-04,   1.66735843e-01,   4.32749046e-04,\n",
       "          9.82346117e-01],\n",
       "       [  4.54864785e-04,   1.19065917e-04,   2.57096201e-01,\n",
       "          1.76051422e-03],\n",
       "       [  1.28666827e-04,   8.96475375e-01,   6.70533348e-03,\n",
       "          9.93396103e-01],\n",
       "       [  5.36119789e-02,   9.11406314e-05,   8.25774610e-01,\n",
       "          4.24298079e-04],\n",
       "       [  8.61061752e-01,   3.34434654e-03,   5.34569030e-04,\n",
       "          9.99330997e-01],\n",
       "       [  9.99450147e-01,   2.84223934e-03,   7.45830119e-01,\n",
       "          2.30529127e-04]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "y_pred = model.predict(test_X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000',\n",
       " '1000',\n",
       " '0100',\n",
       " '0010',\n",
       " '0001',\n",
       " '1100',\n",
       " '1010',\n",
       " '1001',\n",
       " '0110',\n",
       " '0101',\n",
       " '0011',\n",
       " '1110',\n",
       " '1101',\n",
       " '1011',\n",
       " '0111',\n",
       " '1111']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of classes for input to confusion matrix\n",
    "all_permutations = [[0,0,0,0],[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1],[1,1,0,0],[1,0,1,0],[1,0,0,1],[0,1,1,0],[0,1,0,1],[0,0,1,1],[1,1,1,0],[1,1,0,1],[1,0,1,1],[0,1,1,1],[1,1,1,1]]\n",
    "classes = []\n",
    "for label in all_permutations:\n",
    "    val = \"\"\n",
    "    for x in label:\n",
    "        val = val + str(int(x))\n",
    "    classes.append(val)\n",
    "    \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001', '0000', '0010', '0010', '1000', '0000', '0000', '0000', '0101', '1000', '0000', '1101', '0000', '0101', '0000', '0000', '0001', '0000', '0000', '0000', '0100', '0000', '0000', '0000', '1010', '0001', '0000', '0100', '1010', '0011', '0100', '0011', '0000', '0000', '0011', '0000', '0000', '0000', '0010', '0010', '0111', '0000', '0000', '0001', '0000', '0000', '1010', '0001', '0111', '1000', '0000', '0111', '0100', '0000', '0011', '0000', '0001', '0101', '0000', '0000', '0000', '0110', '1011', '1010', '0000', '0001', '0001', '0000', '0101', '0010', '1001', '1000']\n"
     ]
    }
   ],
   "source": [
    "# create y true and y predictions to input into confusion matrix\n",
    "# values must be strings or ints for scikit-learn's confusion matrix, so we must transform them\n",
    "yt = []\n",
    "for label in test_Y:\n",
    "    val = \"\"\n",
    "    for x in label:\n",
    "        val = val + str(int(x))\n",
    "    yt.append(val)\n",
    "    \n",
    "yp = []\n",
    "for label in y_pred:\n",
    "    val = \"\"\n",
    "    for x in label:\n",
    "        \n",
    "        val = val + str(int(0 if x < 0.8 else 1))\n",
    "    yp.append(val)\n",
    "\n",
    "print(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  2,  1,  0,  1,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 1,  1,  0,  2,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  1,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  2,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0,  1,  0,  1,  0,  2,  0,  2,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  1,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(yt, yp)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix with class labels\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[16  2  1  0  1  0  0  1  0  0  1  0  0  0  0]\n",
      " [ 1  1  0  2  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  1  0  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  2  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 3  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  1  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 1  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  1  0  1  0  2  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  1  0  1  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEYCAYAAAAj5FFfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4/HUCXxn5/F46gS+s/N4PHWC/wcYk0T6D4SFLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21cec01acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion, classes=classes, title='Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
