{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv2D, Activation\n",
    "from keras.preprocessing import sequence\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 10\n",
    "time_steps = 6\n",
    "features = 300\n",
    "\n",
    "features_path = 'input_vol.npy'\n",
    "labels_path = 'input_label.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 4)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(features_path)\n",
    "Y = np.load(labels_path)\n",
    "X.shape\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([214,  63, 125,  92, 177, 291, 182,  34, 259, 101,  69,  89, 239,\n",
       "       248, 103, 231, 361, 255, 181,  22,  85, 237,  17,  43, 284, 339,\n",
       "        47,   0, 208, 174, 130, 134, 274, 357, 198, 204, 212, 264, 359,\n",
       "       156,   8,  18,  66,  95, 323, 343, 366, 119, 286, 149, 292, 295,\n",
       "        19, 146, 173, 354, 233, 117, 261, 328, 131, 215, 309, 201, 194,\n",
       "       324, 260, 108, 227, 363, 294,  31, 169, 266,  51, 147,  23, 234,\n",
       "       247, 316, 132, 331, 311,  42, 353, 141,   4,   7, 273,  79,  29,\n",
       "       332, 308,   9,  16,  62, 253,  86, 288, 329, 336, 249, 200, 205,\n",
       "        35, 341, 252, 335, 148, 367,  20, 163, 139, 161, 330, 129,  72,\n",
       "       211, 150,  87, 144, 350,  61,  59, 166, 235, 160, 137, 307, 342,\n",
       "       318, 313,  96,  25, 219, 338,  24,  84, 140, 162,  91,  54,  38,\n",
       "        70,  93, 133, 351,  52, 306, 192, 279, 170,  48, 304,  32, 217,\n",
       "        74, 276, 128, 299,   2, 333, 263, 210, 112,   1, 348, 250, 230,\n",
       "       106, 297, 285,  76, 167, 310, 120, 102, 168,  99, 100, 290, 245,\n",
       "       218,  88, 180, 206, 293, 105,  57, 109, 337, 257, 277, 356, 107,\n",
       "       223,  77, 242,  45, 186, 143, 317, 320,  36,   5, 272,  82, 345,\n",
       "       157, 190,  81,  39, 305,  94, 154, 240, 267, 300, 189, 220,  71,\n",
       "       289, 216,  73, 282, 142, 199, 187, 244, 362, 319,  56, 197, 164,\n",
       "       104, 238, 258, 136,  80, 116,  37, 202, 203, 241, 326,  12, 296,\n",
       "        53, 303, 110,  60, 196,  44, 184, 176,  15,  58, 344, 236, 224,\n",
       "        14, 322, 121, 222, 207, 213, 321, 115, 153,  68, 225, 226, 281,\n",
       "       229, 369,  21,  90, 158, 111, 298,  49, 360, 352, 159,  75,   6,\n",
       "        41,  78, 171, 114, 287,  64, 368, 228, 268,  67, 270, 175,  40,\n",
       "        11,  65, 118, 349, 113, 251, 334, 346, 172, 243,  13, 283,  50,\n",
       "       301,   3, 124, 312,  27, 364,  98, 145, 340, 178, 265, 185,  46,\n",
       "       209, 325, 256, 327, 122,  97,  33,  26, 314,  55, 165, 358, 127,\n",
       "       254, 221, 246, 138, 151, 262, 302, 315, 195, 269, 126,  28, 188,\n",
       "       365, 183, 278, 135, 155, 123, 275, 355, 193, 271,  30, 280, 152,\n",
       "        83, 347, 191, 232,  10, 179])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[s]\n",
    "Y = Y[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[0:296,:,:]\n",
    "test_X = X[297:369,:,:]\n",
    "\n",
    "train_Y = Y[0:296,:]\n",
    "test_Y = Y[297:369,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 160,804\n",
      "Trainable params: 160,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 296 samples, validate on 72 samples\n",
      "Epoch 1/100\n",
      "296/296 [==============================] - 5s - loss: 0.6595 - acc: 0.6985 - val_loss: 0.6160 - val_acc: 0.6944\n",
      "Epoch 2/100\n",
      "296/296 [==============================] - 1s - loss: 0.5600 - acc: 0.7128 - val_loss: 0.5729 - val_acc: 0.7083\n",
      "Epoch 3/100\n",
      "296/296 [==============================] - 2s - loss: 0.5134 - acc: 0.7568 - val_loss: 0.5566 - val_acc: 0.7465\n",
      "Epoch 4/100\n",
      "296/296 [==============================] - 1s - loss: 0.4672 - acc: 0.7694 - val_loss: 0.5549 - val_acc: 0.7535\n",
      "Epoch 5/100\n",
      "296/296 [==============================] - 2s - loss: 0.4222 - acc: 0.7880 - val_loss: 0.5555 - val_acc: 0.7396\n",
      "Epoch 6/100\n",
      "296/296 [==============================] - 2s - loss: 0.3814 - acc: 0.8133 - val_loss: 0.6061 - val_acc: 0.7743\n",
      "Epoch 7/100\n",
      "296/296 [==============================] - 2s - loss: 0.3340 - acc: 0.8556 - val_loss: 0.6341 - val_acc: 0.7778\n",
      "Epoch 8/100\n",
      "296/296 [==============================] - 2s - loss: 0.2937 - acc: 0.8775 - val_loss: 0.6782 - val_acc: 0.7639\n",
      "Epoch 9/100\n",
      "296/296 [==============================] - 1s - loss: 0.2554 - acc: 0.9012 - val_loss: 0.6531 - val_acc: 0.7639\n",
      "Epoch 10/100\n",
      "296/296 [==============================] - 2s - loss: 0.2262 - acc: 0.9096 - val_loss: 0.7240 - val_acc: 0.7396\n",
      "Epoch 11/100\n",
      "296/296 [==============================] - 2s - loss: 0.2058 - acc: 0.9130 - val_loss: 0.7277 - val_acc: 0.7465\n",
      "Epoch 12/100\n",
      "296/296 [==============================] - 2s - loss: 0.1899 - acc: 0.9282 - val_loss: 0.7707 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      "296/296 [==============================] - 1s - loss: 0.1636 - acc: 0.9502 - val_loss: 0.7968 - val_acc: 0.7326\n",
      "Epoch 14/100\n",
      "296/296 [==============================] - 2s - loss: 0.1544 - acc: 0.9493 - val_loss: 0.7894 - val_acc: 0.7535\n",
      "Epoch 15/100\n",
      "296/296 [==============================] - 2s - loss: 0.1322 - acc: 0.9645 - val_loss: 0.8314 - val_acc: 0.7465\n",
      "Epoch 16/100\n",
      "296/296 [==============================] - 2s - loss: 0.1239 - acc: 0.9586 - val_loss: 0.8547 - val_acc: 0.7326\n",
      "Epoch 17/100\n",
      "296/296 [==============================] - 2s - loss: 0.1101 - acc: 0.9645 - val_loss: 0.8872 - val_acc: 0.73960.964\n",
      "Epoch 18/100\n",
      "296/296 [==============================] - 2s - loss: 0.0952 - acc: 0.9730 - val_loss: 0.8414 - val_acc: 0.7604\n",
      "Epoch 19/100\n",
      "296/296 [==============================] - 5s - loss: 0.0811 - acc: 0.9764 - val_loss: 0.9138 - val_acc: 0.7361\n",
      "Epoch 20/100\n",
      "296/296 [==============================] - 2s - loss: 0.0710 - acc: 0.9814 - val_loss: 0.9081 - val_acc: 0.7431\n",
      "Epoch 21/100\n",
      "296/296 [==============================] - 2s - loss: 0.0587 - acc: 0.9890 - val_loss: 0.9314 - val_acc: 0.7535\n",
      "Epoch 22/100\n",
      "296/296 [==============================] - 2s - loss: 0.0504 - acc: 0.9907 - val_loss: 0.9497 - val_acc: 0.7465\n",
      "Epoch 23/100\n",
      "296/296 [==============================] - 2s - loss: 0.0446 - acc: 0.9916 - val_loss: 0.9778 - val_acc: 0.7431\n",
      "Epoch 24/100\n",
      "296/296 [==============================] - 2s - loss: 0.0393 - acc: 0.9916 - val_loss: 0.9860 - val_acc: 0.7535\n",
      "Epoch 25/100\n",
      "296/296 [==============================] - 2s - loss: 0.0371 - acc: 0.9924 - val_loss: 1.0061 - val_acc: 0.7465\n",
      "Epoch 26/100\n",
      "296/296 [==============================] - 2s - loss: 0.0460 - acc: 0.9873 - val_loss: 1.0293 - val_acc: 0.7569\n",
      "Epoch 27/100\n",
      "296/296 [==============================] - 2s - loss: 0.0394 - acc: 0.9899 - val_loss: 1.0308 - val_acc: 0.7569\n",
      "Epoch 28/100\n",
      "296/296 [==============================] - 2s - loss: 0.0318 - acc: 0.9924 - val_loss: 1.0662 - val_acc: 0.7535\n",
      "Epoch 29/100\n",
      "296/296 [==============================] - 2s - loss: 0.0304 - acc: 0.9941 - val_loss: 1.0703 - val_acc: 0.7535\n",
      "Epoch 30/100\n",
      "296/296 [==============================] - 2s - loss: 0.0293 - acc: 0.9932 - val_loss: 1.0812 - val_acc: 0.7569\n",
      "Epoch 31/100\n",
      "296/296 [==============================] - 2s - loss: 0.0485 - acc: 0.9856 - val_loss: 1.1783 - val_acc: 0.7222\n",
      "Epoch 32/100\n",
      "296/296 [==============================] - 2s - loss: 0.1421 - acc: 0.9476 - val_loss: 1.0284 - val_acc: 0.7569\n",
      "Epoch 33/100\n",
      "296/296 [==============================] - 2s - loss: 0.1017 - acc: 0.9696 - val_loss: 0.9928 - val_acc: 0.7604\n",
      "Epoch 34/100\n",
      "296/296 [==============================] - 1s - loss: 0.0779 - acc: 0.9772 - val_loss: 0.9688 - val_acc: 0.7535\n",
      "Epoch 35/100\n",
      "296/296 [==============================] - 1s - loss: 0.0465 - acc: 0.9890 - val_loss: 1.0008 - val_acc: 0.7465\n",
      "Epoch 36/100\n",
      "296/296 [==============================] - 6s - loss: 0.0340 - acc: 0.9924 - val_loss: 1.0343 - val_acc: 0.7535\n",
      "Epoch 37/100\n",
      "296/296 [==============================] - 8s - loss: 0.0311 - acc: 0.9941 - val_loss: 1.0306 - val_acc: 0.7535\n",
      "Epoch 38/100\n",
      "296/296 [==============================] - 8s - loss: 0.0280 - acc: 0.9941 - val_loss: 1.0402 - val_acc: 0.7396\n",
      "Epoch 39/100\n",
      "296/296 [==============================] - 8s - loss: 0.0247 - acc: 0.9932 - val_loss: 1.0639 - val_acc: 0.7569\n",
      "Epoch 40/100\n",
      "296/296 [==============================] - 9s - loss: 0.0207 - acc: 0.9941 - val_loss: 1.0852 - val_acc: 0.7535\n",
      "Epoch 41/100\n",
      "296/296 [==============================] - 10s - loss: 0.0238 - acc: 0.9924 - val_loss: 1.0738 - val_acc: 0.7639\n",
      "Epoch 42/100\n",
      "296/296 [==============================] - 9s - loss: 0.0201 - acc: 0.9949 - val_loss: 1.1142 - val_acc: 0.7569\n",
      "Epoch 43/100\n",
      "296/296 [==============================] - 10s - loss: 0.0176 - acc: 0.9941 - val_loss: 1.1114 - val_acc: 0.7639\n",
      "Epoch 44/100\n",
      "296/296 [==============================] - 10s - loss: 0.0165 - acc: 0.9958 - val_loss: 1.1213 - val_acc: 0.7535\n",
      "Epoch 45/100\n",
      "296/296 [==============================] - 9s - loss: 0.0161 - acc: 0.9958 - val_loss: 1.1329 - val_acc: 0.7569\n",
      "Epoch 46/100\n",
      "296/296 [==============================] - 10s - loss: 0.0153 - acc: 0.9949 - val_loss: 1.1441 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      "296/296 [==============================] - 9s - loss: 0.0145 - acc: 0.9958 - val_loss: 1.1563 - val_acc: 0.7535\n",
      "Epoch 48/100\n",
      "296/296 [==============================] - 495s - loss: 0.0145 - acc: 0.9949 - val_loss: 1.1647 - val_acc: 0.7639\n",
      "Epoch 49/100\n",
      "296/296 [==============================] - 2s - loss: 0.0145 - acc: 0.9949 - val_loss: 1.1686 - val_acc: 0.7535\n",
      "Epoch 50/100\n",
      "296/296 [==============================] - 14s - loss: 0.0143 - acc: 0.9958 - val_loss: 1.1766 - val_acc: 0.7604\n",
      "Epoch 51/100\n",
      "296/296 [==============================] - 8s - loss: 0.0153 - acc: 0.9949 - val_loss: 1.2028 - val_acc: 0.7569\n",
      "Epoch 52/100\n",
      "296/296 [==============================] - 5s - loss: 0.0140 - acc: 0.9958 - val_loss: 1.2040 - val_acc: 0.7465\n",
      "Epoch 53/100\n",
      "296/296 [==============================] - 4s - loss: 0.0134 - acc: 0.9932 - val_loss: 1.2148 - val_acc: 0.7535\n",
      "Epoch 54/100\n",
      "296/296 [==============================] - 5s - loss: 0.0124 - acc: 0.9958 - val_loss: 1.2223 - val_acc: 0.7500\n",
      "Epoch 55/100\n",
      "296/296 [==============================] - 3s - loss: 0.0173 - acc: 0.9932 - val_loss: 1.2358 - val_acc: 0.7535\n",
      "Epoch 56/100\n",
      "296/296 [==============================] - 3s - loss: 0.0138 - acc: 0.9958 - val_loss: 1.2221 - val_acc: 0.7535\n",
      "Epoch 57/100\n",
      "296/296 [==============================] - 2s - loss: 0.0125 - acc: 0.9958 - val_loss: 1.2413 - val_acc: 0.7569\n",
      "Epoch 58/100\n",
      "296/296 [==============================] - 2s - loss: 0.0118 - acc: 0.9958 - val_loss: 1.2698 - val_acc: 0.7535\n",
      "Epoch 59/100\n",
      "296/296 [==============================] - 2s - loss: 0.0131 - acc: 0.9958 - val_loss: 1.2744 - val_acc: 0.7535\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 2s - loss: 0.0121 - acc: 0.9949 - val_loss: 1.2831 - val_acc: 0.7569\n",
      "Epoch 61/100\n",
      "296/296 [==============================] - 2s - loss: 0.0116 - acc: 0.9949 - val_loss: 1.2910 - val_acc: 0.7535\n",
      "Epoch 62/100\n",
      "296/296 [==============================] - 2s - loss: 0.0109 - acc: 0.9958 - val_loss: 1.2978 - val_acc: 0.7535\n",
      "Epoch 63/100\n",
      "296/296 [==============================] - 1s - loss: 0.0121 - acc: 0.9949 - val_loss: 1.2889 - val_acc: 0.7535\n",
      "Epoch 64/100\n",
      "296/296 [==============================] - 2s - loss: 0.0109 - acc: 0.9966 - val_loss: 1.3098 - val_acc: 0.7535\n",
      "Epoch 65/100\n",
      "296/296 [==============================] - 1s - loss: 0.0106 - acc: 0.9966 - val_loss: 1.3231 - val_acc: 0.7535\n",
      "Epoch 66/100\n",
      "296/296 [==============================] - 2s - loss: 0.0102 - acc: 0.9966 - val_loss: 1.3326 - val_acc: 0.7535\n",
      "Epoch 67/100\n",
      "296/296 [==============================] - 1s - loss: 0.0100 - acc: 0.9966 - val_loss: 1.3391 - val_acc: 0.7535\n",
      "Epoch 68/100\n",
      "296/296 [==============================] - 1s - loss: 0.0098 - acc: 0.9958 - val_loss: 1.3429 - val_acc: 0.7535\n",
      "Epoch 69/100\n",
      "296/296 [==============================] - 2s - loss: 0.0099 - acc: 0.9966 - val_loss: 1.3343 - val_acc: 0.7465\n",
      "Epoch 70/100\n",
      "296/296 [==============================] - 2s - loss: 0.0141 - acc: 0.9932 - val_loss: 1.3305 - val_acc: 0.7465\n",
      "Epoch 71/100\n",
      "296/296 [==============================] - 2s - loss: 0.0423 - acc: 0.9899 - val_loss: 1.3701 - val_acc: 0.7257\n",
      "Epoch 72/100\n",
      "296/296 [==============================] - 1s - loss: 0.0570 - acc: 0.9806 - val_loss: 1.3116 - val_acc: 0.7361\n",
      "Epoch 73/100\n",
      "296/296 [==============================] - 1s - loss: 0.0406 - acc: 0.9823 - val_loss: 1.2423 - val_acc: 0.7604\n",
      "Epoch 74/100\n",
      "296/296 [==============================] - 1s - loss: 0.0584 - acc: 0.9823 - val_loss: 1.3688 - val_acc: 0.7465\n",
      "Epoch 75/100\n",
      "296/296 [==============================] - 1s - loss: 0.0428 - acc: 0.9840 - val_loss: 1.2639 - val_acc: 0.7465\n",
      "Epoch 76/100\n",
      "296/296 [==============================] - 2s - loss: 0.0191 - acc: 0.9941 - val_loss: 1.2084 - val_acc: 0.7639\n",
      "Epoch 77/100\n",
      "296/296 [==============================] - 2s - loss: 0.0268 - acc: 0.9924 - val_loss: 1.2353 - val_acc: 0.7396\n",
      "Epoch 78/100\n",
      "296/296 [==============================] - 2s - loss: 0.0210 - acc: 0.9916 - val_loss: 1.2413 - val_acc: 0.7708\n",
      "Epoch 79/100\n",
      "296/296 [==============================] - 1s - loss: 0.0147 - acc: 0.9949 - val_loss: 1.2350 - val_acc: 0.7743\n",
      "Epoch 80/100\n",
      "296/296 [==============================] - 1s - loss: 0.0128 - acc: 0.9941 - val_loss: 1.2518 - val_acc: 0.7708\n",
      "Epoch 81/100\n",
      "296/296 [==============================] - 1s - loss: 0.0117 - acc: 0.9958 - val_loss: 1.2524 - val_acc: 0.7639\n",
      "Epoch 82/100\n",
      "296/296 [==============================] - 1s - loss: 0.0108 - acc: 0.9949 - val_loss: 1.2623 - val_acc: 0.7708\n",
      "Epoch 83/100\n",
      "296/296 [==============================] - 1s - loss: 0.0103 - acc: 0.9958 - val_loss: 1.2707 - val_acc: 0.7674\n",
      "Epoch 84/100\n",
      "296/296 [==============================] - 1s - loss: 0.0099 - acc: 0.9949 - val_loss: 1.2773 - val_acc: 0.7674\n",
      "Epoch 85/100\n",
      "296/296 [==============================] - 1s - loss: 0.0098 - acc: 0.9949 - val_loss: 1.2837 - val_acc: 0.76390.9\n",
      "Epoch 86/100\n",
      "296/296 [==============================] - 1s - loss: 0.0093 - acc: 0.9966 - val_loss: 1.2883 - val_acc: 0.7604\n",
      "Epoch 87/100\n",
      "296/296 [==============================] - 1s - loss: 0.0093 - acc: 0.9966 - val_loss: 1.2899 - val_acc: 0.7604\n",
      "Epoch 88/100\n",
      "296/296 [==============================] - 1s - loss: 0.0090 - acc: 0.9958 - val_loss: 1.2945 - val_acc: 0.7604\n",
      "Epoch 89/100\n",
      "296/296 [==============================] - 1s - loss: 0.0088 - acc: 0.9966 - val_loss: 1.2968 - val_acc: 0.76040.996\n",
      "Epoch 90/100\n",
      "296/296 [==============================] - 1s - loss: 0.0087 - acc: 0.9958 - val_loss: 1.3006 - val_acc: 0.7604\n",
      "Epoch 91/100\n",
      "296/296 [==============================] - 1s - loss: 0.0085 - acc: 0.9958 - val_loss: 1.3043 - val_acc: 0.7569\n",
      "Epoch 92/100\n",
      "296/296 [==============================] - 1s - loss: 0.0084 - acc: 0.9958 - val_loss: 1.3081 - val_acc: 0.7535\n",
      "Epoch 93/100\n",
      "296/296 [==============================] - 1s - loss: 0.0081 - acc: 0.9966 - val_loss: 1.3083 - val_acc: 0.7535\n",
      "Epoch 94/100\n",
      "296/296 [==============================] - 1s - loss: 0.0080 - acc: 0.9966 - val_loss: 1.3159 - val_acc: 0.7535\n",
      "Epoch 95/100\n",
      "296/296 [==============================] - 1s - loss: 0.0077 - acc: 0.9958 - val_loss: 1.3200 - val_acc: 0.7535\n",
      "Epoch 96/100\n",
      "296/296 [==============================] - 1s - loss: 0.0077 - acc: 0.9958 - val_loss: 1.3233 - val_acc: 0.7500\n",
      "Epoch 97/100\n",
      "296/296 [==============================] - 1s - loss: 0.0077 - acc: 0.9966 - val_loss: 1.3375 - val_acc: 0.7465\n",
      "Epoch 98/100\n",
      "296/296 [==============================] - 1s - loss: 0.0075 - acc: 0.9966 - val_loss: 1.3380 - val_acc: 0.7500\n",
      "Epoch 99/100\n",
      "296/296 [==============================] - 2s - loss: 0.0074 - acc: 0.9958 - val_loss: 1.3397 - val_acc: 0.7535\n",
      "Epoch 100/100\n",
      "296/296 [==============================] - 2s - loss: 0.0074 - acc: 0.9949 - val_loss: 1.3485 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc1b767cc0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build LSTM layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(time_steps, features)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(train_X, train_Y, validation_data=(test_X, test_Y), epochs=epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "# score model and log accuracy and parameters\n",
    "scores = model.evaluate(test_X, test_Y, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.44e-03,   1.14e-03,   9.97e-01,   9.99e-01],\n",
       "       [  4.60e-04,   1.63e-04,   2.87e-03,   1.42e-04],\n",
       "       [  4.66e-04,   7.35e-05,   1.00e+00,   9.90e-04],\n",
       "       ..., \n",
       "       [  3.24e-04,   1.13e-04,   4.31e-03,   8.01e-05],\n",
       "       [  3.22e-04,   3.76e-04,   2.12e-03,   2.10e-04],\n",
       "       [  1.20e-03,   9.43e-04,   9.99e-01,   9.97e-01]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(train_X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000',\n",
       " '1000',\n",
       " '0100',\n",
       " '0010',\n",
       " '0001',\n",
       " '1100',\n",
       " '1010',\n",
       " '1001',\n",
       " '0110',\n",
       " '0101',\n",
       " '0011',\n",
       " '1110',\n",
       " '1101',\n",
       " '1011',\n",
       " '0111',\n",
       " '1111']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_permutations = [[0,0,0,0],[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1],[1,1,0,0],[1,0,1,0],[1,0,0,1],[0,1,1,0],[0,1,0,1],[0,0,1,1],[1,1,1,0],[1,1,0,1],[1,0,1,1],[0,1,1,1],[1,1,1,1]]\n",
    "classes = []\n",
    "for label in all_permutations:\n",
    "    val = \"\"\n",
    "    for x in label:\n",
    "        val = val + str(int(x))\n",
    "    classes.append(val)\n",
    "    \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0011', '0000', '0010', '0000', '1001', '0100', '1100', '0000', '0010', '0000', '0000', '1000', '0000', '0000', '0011', '0100', '0010', '0000', '1100', '0110', '0000', '1000', '0000', '0000', '0001', '0100', '1010', '0000', '0000', '0001', '1100', '0001', '0011', '0011', '0000', '0000', '0101', '0001', '0011', '1000', '1111', '1011', '1010', '1000', '0010', '0101', '0010', '0001', '0101', '0000', '0000', '0011', '1011', '0111', '0000', '0010', '0010', '1000', '0000', '0111', '1000', '0000', '0111', '1000', '0011', '0010', '0000', '1011', '0010', '1110', '1010', '0111', '0001', '0000', '1110', '0010', '1010', '0111', '0000', '1010', '0001', '0110', '0010', '0011', '0000', '0000', '1000', '1110', '0111', '1000', '0000', '1111', '0001', '1100', '1010', '1110', '1010', '0100', '1010', '0100', '1000', '0000', '0000', '0000', '0000', '0010', '1111', '0110', '0001', '0010', '0000', '0000', '0000', '0001', '0000', '1001', '0000', '0100', '0111', '1010', '0000', '0100', '0000', '0001', '0010', '1010', '0101', '0001', '0101', '0000', '0111', '0101', '0000', '1000', '0000', '1011', '0000', '0000', '1110', '0000', '0011', '0000', '1101', '0000', '0000', '0001', '0011', '0011', '0001', '0111', '1110', '1100', '0000', '0000', '0000', '1110', '1010', '0000', '0001', '1000', '0000', '0010', '0010', '1000', '0001', '1000', '0100', '0000', '0110', '0101', '0000', '1000', '0000', '0010', '0101', '1000', '1011', '0010', '0000', '0011', '0000', '0100', '0000', '0000', '0001', '1100', '0000', '1010', '1000', '0000', '1101', '0000', '1001', '0000', '0000', '0000', '0001', '1000', '0000', '0000', '0111', '1000', '0010', '0000', '1000', '0010', '0000', '1000', '0010', '1111', '0000', '0000', '0000', '1010', '0000', '1000', '0000', '0110', '0001', '1011', '1100', '1000', '0101', '1000', '0000', '0101', '0000', '0000', '0001', '1000', '0011', '0000', '0000', '1010', '0010', '1110', '0000', '0001', '0010', '0010', '0000', '1100', '1010', '1000', '0101', '1000', '1101', '0000', '0100', '1000', '0011', '0000', '0010', '0000', '0101', '0000', '0000', '0101', '0000', '0101', '1010', '1010', '0000', '0000', '0110', '0001', '1100', '1011', '0011', '0000', '1000', '0101', '0011', '0100', '1000', '0000', '0000', '0000', '1010', '0000', '0000', '1010', '0111', '0101', '0001', '1010', '1010', '0000', '1000', '1011', '0000', '0000', '1000', '0000', '0000', '0011']\n"
     ]
    }
   ],
   "source": [
    "all_permutations = [[0,0,0,0],[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1],[1,1,0,0],[1,0,1,0],[1,0,0,1],[0,1,1,0],[0,1,0,1],[0,0,1,1],[1,1,1,0],[1,1,0,1],[1,0,1,1],[0,1,1,1],[1,1,1,1]]\n",
    "\n",
    "#test_Y\n",
    "#test_Y_int = int()\n",
    "\n",
    "yt = []\n",
    "for label in train_Y:\n",
    "    val = \"\"\n",
    "    for x in label:\n",
    "        val = val + str(int(x))\n",
    "    yt.append(val)\n",
    "    \n",
    "yp = []\n",
    "for label in y_pred:\n",
    "    val = \"\"\n",
    "    for x in label:\n",
    "        \n",
    "        val = val + str(int(0 if x < 0.8 else 1))\n",
    "    yp.append(val)\n",
    "\n",
    "print(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.50386836e-04,   1.76426576e-04,   2.29783691e-04,\n",
       "          1.05401727e-04],\n",
       "       [  6.29448751e-03,   9.25230622e-01,   1.02306344e-02,\n",
       "          9.20062757e-06],\n",
       "       [  3.97565600e-04,   1.18106458e-04,   2.80234759e-04,\n",
       "          8.57506384e-05],\n",
       "       [  1.51176599e-03,   2.94314144e-04,   9.99193490e-01,\n",
       "          8.15222680e-04],\n",
       "       [  1.32543757e-03,   1.94036198e-04,   9.97405231e-01,\n",
       "          2.41353584e-04],\n",
       "       [  3.60165897e-04,   1.26668296e-04,   6.20792853e-04,\n",
       "          4.72697866e-05],\n",
       "       [  1.70643313e-03,   1.53630285e-03,   9.98314500e-01,\n",
       "          7.24751008e-05],\n",
       "       [  9.97605562e-01,   9.12433374e-04,   2.56080879e-04,\n",
       "          7.27191975e-04],\n",
       "       [  1.43228055e-04,   2.46124662e-04,   2.23926525e-03,\n",
       "          1.06840380e-04],\n",
       "       [  7.22484780e-04,   6.03962631e-04,   9.99409676e-01,\n",
       "          9.99017358e-01],\n",
       "       [  6.56238000e-04,   5.75788494e-04,   9.99329805e-01,\n",
       "          9.98988330e-01],\n",
       "       [  6.68844790e-04,   6.21255138e-04,   9.99412775e-01,\n",
       "          9.98956680e-01],\n",
       "       [  6.84796891e-04,   6.03219320e-04,   9.99407172e-01,\n",
       "          9.98954654e-01],\n",
       "       [  5.77717437e-04,   7.41659605e-04,   9.99474108e-01,\n",
       "          9.98813629e-01],\n",
       "       [  9.73815040e-04,   7.19496282e-04,   9.99344289e-01,\n",
       "          9.99269783e-01],\n",
       "       [  7.30796484e-04,   5.94827929e-04,   9.99337614e-01,\n",
       "          9.99079108e-01],\n",
       "       [  8.52488697e-01,   9.95653510e-01,   7.32237677e-05,\n",
       "          4.99416259e-04],\n",
       "       [  3.12620599e-04,   1.29990542e-04,   2.31992773e-04,\n",
       "          1.15732029e-04],\n",
       "       [  4.01018420e-04,   3.43215070e-04,   9.97146666e-01,\n",
       "          2.39503206e-04],\n",
       "       [  9.99665141e-01,   6.34458265e-04,   6.57584285e-03,\n",
       "          2.01356597e-03],\n",
       "       [  4.31765046e-04,   1.14852955e-04,   2.65316572e-04,\n",
       "          8.62930974e-05],\n",
       "       [  9.74354800e-04,   1.17126619e-03,   9.99235749e-01,\n",
       "          9.99382496e-01],\n",
       "       [  2.05399059e-02,   9.99591768e-01,   9.93510306e-01,\n",
       "          9.98902321e-01],\n",
       "       [  9.99706447e-01,   2.78702378e-03,   9.99307036e-01,\n",
       "          1.85909450e-01],\n",
       "       [  9.24290597e-01,   8.11590580e-04,   9.99795258e-01,\n",
       "          2.23455136e-04],\n",
       "       [  9.98231828e-01,   5.65802329e-04,   8.31208134e-04,\n",
       "          1.24026788e-03],\n",
       "       [  9.99780118e-01,   3.07749608e-03,   2.53631204e-01,\n",
       "          3.66243388e-04],\n",
       "       [  3.82355660e-01,   9.96415734e-01,   3.12681077e-04,\n",
       "          9.97190177e-01],\n",
       "       [  1.25522181e-01,   9.98576880e-01,   9.95514333e-01,\n",
       "          9.99586523e-01],\n",
       "       [  2.97824707e-04,   9.98439968e-01,   5.63552380e-01,\n",
       "          9.98974562e-01],\n",
       "       [  3.65533197e-04,   3.42124753e-04,   9.98251617e-01,\n",
       "          5.97763341e-04],\n",
       "       [  1.30310585e-03,   1.20224163e-03,   9.99674559e-01,\n",
       "          9.99044359e-01],\n",
       "       [  2.02298583e-03,   4.05383849e-04,   9.99446094e-01,\n",
       "          8.47976946e-04],\n",
       "       [  8.04710071e-05,   1.49324653e-04,   3.75012372e-04,\n",
       "          9.51502860e-01],\n",
       "       [  8.17077875e-04,   1.81363255e-04,   4.53989487e-03,\n",
       "          9.99440134e-01],\n",
       "       [  9.98406947e-01,   2.97051651e-04,   9.99371231e-01,\n",
       "          1.08734928e-02],\n",
       "       [  2.18676925e-02,   3.14793113e-04,   9.99600112e-01,\n",
       "          4.41090000e-04],\n",
       "       [  9.94424045e-01,   1.48684194e-03,   9.99712765e-01,\n",
       "          4.16146620e-04],\n",
       "       [  2.32140407e-01,   1.54087800e-04,   9.99307871e-01,\n",
       "          8.55365011e-04],\n",
       "       [  9.89136577e-01,   1.57057817e-04,   7.53140426e-04,\n",
       "          9.80705605e-04],\n",
       "       [  9.89273489e-01,   8.42923298e-04,   2.13696256e-01,\n",
       "          9.99412656e-01],\n",
       "       [  9.98527050e-01,   9.99373734e-01,   9.98907328e-01,\n",
       "          1.21244579e-03],\n",
       "       [  4.81388997e-03,   2.95931548e-01,   2.54448794e-04,\n",
       "          9.98859644e-01],\n",
       "       [  5.45742747e-04,   9.99245644e-01,   3.75353062e-04,\n",
       "          9.59556818e-01],\n",
       "       [  9.99841213e-01,   4.56606591e-04,   9.97592866e-01,\n",
       "          4.87972936e-03],\n",
       "       [  2.73124198e-04,   1.36821822e-04,   1.93751868e-04,\n",
       "          1.47748273e-04],\n",
       "       [  9.93908763e-01,   1.29809463e-03,   1.90819777e-03,\n",
       "          9.96298373e-01],\n",
       "       [  5.54494443e-04,   3.21544430e-05,   2.84128785e-02,\n",
       "          9.03113032e-05],\n",
       "       [  9.99888420e-01,   5.76986730e-01,   9.98539209e-01,\n",
       "          3.74744326e-01],\n",
       "       [  9.99210835e-01,   9.93947506e-01,   6.71814755e-03,\n",
       "          2.50824000e-04],\n",
       "       [  2.54860073e-02,   9.92401600e-01,   6.09040508e-05,\n",
       "          2.51599064e-04],\n",
       "       [  9.97774661e-01,   2.02213690e-04,   9.94518578e-01,\n",
       "          9.60309088e-01],\n",
       "       [  9.99510646e-01,   6.28546753e-04,   9.90131140e-01,\n",
       "          9.70221937e-01],\n",
       "       [  9.97774661e-01,   2.02213690e-04,   9.94518578e-01,\n",
       "          9.60309088e-01],\n",
       "       [  1.72927529e-02,   9.99224067e-01,   9.92566109e-01,\n",
       "          9.99589026e-01],\n",
       "       [  8.06617318e-04,   1.02026104e-04,   7.62946496e-04,\n",
       "          9.99259770e-01],\n",
       "       [  4.35787340e-04,   1.14096052e-04,   2.66687566e-04,\n",
       "          8.60227883e-05],\n",
       "       [  9.97826993e-01,   4.50197549e-04,   1.40683714e-03,\n",
       "          5.67054900e-04],\n",
       "       [  8.97275633e-04,   5.45218412e-04,   5.65943483e-05,\n",
       "          9.89433229e-01],\n",
       "       [  3.21949337e-04,   1.52599896e-04,   1.75310255e-04,\n",
       "          1.37322684e-04],\n",
       "       [  7.08424021e-04,   3.08762828e-04,   9.96909797e-01,\n",
       "          9.99269664e-01],\n",
       "       [  3.86409200e-04,   4.45552578e-04,   9.97850299e-01,\n",
       "          9.99029517e-01],\n",
       "       [  9.99791086e-01,   4.65113058e-04,   9.97725546e-01,\n",
       "          6.66135130e-03],\n",
       "       [  2.45775163e-01,   1.17946423e-04,   1.68862648e-03,\n",
       "          9.99498367e-01],\n",
       "       [  2.04504691e-02,   8.38760566e-03,   9.99898791e-01,\n",
       "          3.01093445e-03],\n",
       "       [  2.00328388e-04,   1.50821448e-04,   2.78195366e-04,\n",
       "          1.77851092e-04],\n",
       "       [  9.99781072e-01,   3.69711630e-02,   9.98877466e-01,\n",
       "          9.89991963e-01],\n",
       "       [  9.99623895e-01,   2.16289964e-02,   9.99749601e-01,\n",
       "          3.38812429e-03],\n",
       "       [  3.76266107e-04,   1.06287487e-04,   3.31537070e-04,\n",
       "          8.82637687e-05],\n",
       "       [  9.68172669e-01,   9.51988841e-05,   1.55334536e-03,\n",
       "          5.79752319e-04],\n",
       "       [  2.09149948e-04,   4.80603703e-05,   1.97625184e-03,\n",
       "          1.90822626e-04],\n",
       "       [  9.98867750e-01,   1.46239850e-04,   9.96706188e-01,\n",
       "          7.42627401e-03]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 11,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 32,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 21,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  9,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(yt, yp)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[98  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 23  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 25  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1 16  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEYCAYAAAAj5FFfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc1a12d390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion, classes=classes,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(confusion, classes=classes, normalize=True,\n",
    "#                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
